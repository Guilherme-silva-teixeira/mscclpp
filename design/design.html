<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MSCCL++ Design Document &mdash; mscclpp v0.5.2 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=0dc63f2a"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="NCCL Over MSCCL++" href="nccl-over-mscclpp.html" />
    <link rel="prev" title="Working with Python API" href="../getting-started/tutorials/python-api.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            mscclpp
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../getting-started/tutorials/index.html">Tutorials</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Design</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">MSCCL++ Design Document</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#concepts">Concepts</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#channel">Channel</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#smchannel-proxychannel">SmChannel &amp; ProxyChannel</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#fifo-trigger">Fifo &amp; Trigger</a></li>
<li class="toctree-l3"><a class="reference internal" href="#proxyservice">ProxyService</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#implementation">Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#interfaces">Interfaces</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#communication-setup-and-initialization-apis">Communication setup and initialization APIs</a></li>
<li class="toctree-l4"><a class="reference internal" href="#msccl-kernel-programming-model">MSCCL++ kernel programming model</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#the-mechanism-for-offloading-communication-logic-from-the-gpu-to-the-cpu">The mechanism for offloading communication logic from the GPU to the CPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#use-cases">Use Cases</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#overlapping-communication-with-computation">Overlapping communication with computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fusion-of-communication-and-computation">Fusion of communication and computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#implementing-customized-collective-communication-algorithms">Implementing customized collective communication algorithms</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="nccl-over-mscclpp.html">NCCL Over MSCCL++</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Performance</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../performance/performance-ndmv4.html">NDmv4 Performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">C++ API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">mscclpp</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">MSCCL++ Design Document</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/design/design.md.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="msccl-design-document">
<h1>MSCCL++ Design Document<a class="headerlink" href="#msccl-design-document" title="Permalink to this heading"></a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>MSCCL++ redefines inter-GPU communication interfaces, thereby delivering a highly efficient and customizable communication stack for distributed GPU applications. Its design is specifically tailored to accommodate diverse performance optimization scenarios often encountered in state-of-the-art AI applications. The figure below provides a high-level overview of MSCCL++ abstractions in CUDA, C, and Python.</p>
<figure class="align-center" id="msccl-abstractions">
<img alt="MSCCL++ Abstractions" src="../_images/abstractions.png" />
<figcaption>
<p><span class="caption-text">MSCCL++ Abstractions Overview</span><a class="headerlink" href="#msccl-abstractions" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The followings highlight the key features of MSCCL++.</p>
<ul class="simple">
<li><p><strong>Light-weight and multi-layer abstractions.</strong> MSCCL++ provides communication abstractions at lowest level close to hardware and at the highest level close to application API. The lowest level of abstraction is ultra light weight which enables a user to implement logics of data movement for a collective operation such as AllReduce inside a GPU kernel extremely efficiently without worrying about memory ordering of different ops. The modularity of MSCCL++ enables a user to construct the building blocks of MSCCL++ in a high level abstraction in Python and feed them to a CUDA kernel in order to facilitate the user’s productivity.</p></li>
<li><p><strong>1-sided 0-copy synchronous and asynchronous abstracts.</strong> MSCCL++ provides fine-grained synchronous and asynchronous 0-copy 1-sided abstracts for communication primitives such as <code class="docutils literal notranslate"><span class="pre">put()</span></code>, <code class="docutils literal notranslate"><span class="pre">get()</span></code>, <code class="docutils literal notranslate"><span class="pre">signal()</span></code>, <code class="docutils literal notranslate"><span class="pre">flush()</span></code>, and <code class="docutils literal notranslate"><span class="pre">wait()</span></code>. The 1-sided abstractions allows a user to asynchronously <code class="docutils literal notranslate"><span class="pre">put()</span></code> their data on the remote GPU as soon as it is ready without requiring the remote side to issue any receive instruction. This enables users to easily implement flexible communication logics, such as overlapping communication with computation, or implementing customized collective communication algorithms without worrying about potential deadlocks. Additionally, the 0-copy capability enables MSCCL++ to directly transfer data between user’s buffers without using intermediate internal buffers which saves GPU bandwidth and memory capacity.</p></li>
<li><p><strong>Unified abstractions for different interconnection hardware.</strong> MSCCL++ provides consistent abstractions regardless of the location of the remote GPU (either on the local node or on a remote node) or the underlying link (either NVLink/xGMI or InfiniBand). This simplifies the code for inter-GPU communication, which is often complex due to memory ordering of GPU/CPU read/writes and therefore, is error-prone.</p></li>
</ul>
</section>
<section id="concepts">
<h2>Concepts<a class="headerlink" href="#concepts" title="Permalink to this heading"></a></h2>
<p>To implement the list of features above, some concepts are introduced.</p>
<section id="channel">
<h3>Channel<a class="headerlink" href="#channel" title="Permalink to this heading"></a></h3>
<p>MSCCL++ provides peer-to-peer communication methods between GPUs. A peer-to-peer connection between two GPUs is called a <em>Channel</em>. Channels are constructed by MSCCL++ host-side interfaces and copied to GPUs during initialization. Channels provide <em>GPU-side interfaces</em>, which means that all communication methods are defined as a device function to be called from a GPU kernel code. Following code shows the basic usage for channel, the <code class="docutils literal notranslate"><span class="pre">put()</span></code> method in the following code copies 1KB data from the local GPU to a remote GPU.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__global__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">gpuKernel</span><span class="p">()</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="p">...</span>
<span class="w">  </span><span class="c1">// Only one thread is needed for this method.</span>
<span class="w">  </span><span class="n">channel</span><span class="p">.</span><span class="n">put</span><span class="p">(</span><span class="cm">/*dstOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*srcOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*size=*/</span><span class="w"> </span><span class="mi">1024</span><span class="p">);</span>
<span class="w">  </span><span class="p">...</span>
<span class="p">}</span>
</pre></div>
</div>
<p>MSCCL++ also provides efficient synchronization methods, <code class="docutils literal notranslate"><span class="pre">signal()</span></code>, <code class="docutils literal notranslate"><span class="pre">flush()</span></code>, and <code class="docutils literal notranslate"><span class="pre">wait()</span></code>. We will discuss these methods in the following sections.</p>
<section id="smchannel-proxychannel">
<h4>SmChannel &amp; ProxyChannel<a class="headerlink" href="#smchannel-proxychannel" title="Permalink to this heading"></a></h4>
<p>MSCCL++ delivers two types of channels, <strong>ProxyChannel</strong> and <strong>SmChannel</strong>. <code class="docutils literal notranslate"><span class="pre">ProxyChannel</span></code> provides (R)DMA-based data copy and synchronization methods. When called, these methods send/receive a signal to/from a host-side proxy (hence the name <code class="docutils literal notranslate"><span class="pre">ProxyChannel</span></code>), which will trigger (R)DMA (such as <code class="docutils literal notranslate"><span class="pre">cudaMemcpy*</span></code> or <code class="docutils literal notranslate"><span class="pre">ibv_post_send</span></code>) or issue synchronization methods (such as <code class="docutils literal notranslate"><span class="pre">cudaStreamSynchronize</span></code> or <code class="docutils literal notranslate"><span class="pre">ibv_poll_cq</span></code>). Since the key functionalities are run by the proxy, ProxyChannel requires only a single GPU thread to call its methods. See all <code class="docutils literal notranslate"><span class="pre">ProxyChannel</span></code> methods from <a class="reference external" href="https://github.com/microsoft/mscclpp/blob/main/include/mscclpp/proxy_channel_device.hpp">here</a>.</p>
<p>On the other hand, <code class="docutils literal notranslate"><span class="pre">SmChannel</span></code> provides memory-mapping-based copy and synchronization methods. When called, these methods will directly use GPU threads to read/write from/to the remote GPU’s memory space. Comparing against ProxyChannel, SmChannel is especially performant for low-latency scenarios, while it may need many GPU threads to call copying methods at the same time to achieve high copying bandwidth. See all SmChannel methods from <a class="reference external" href="https://github.com/microsoft/mscclpp/blob/main/include/mscclpp/sm_channel_device.hpp">here</a>.</p>
</section>
</section>
<section id="fifo-trigger">
<h3>Fifo &amp; Trigger<a class="headerlink" href="#fifo-trigger" title="Permalink to this heading"></a></h3>
<p>One of the key features of MSCCL++ is to offload the communication logic from the GPU to the CPU.
To offload the communication logic from the GPU to the CPU, MSCCL++ introduces the concept of <code class="docutils literal notranslate"><span class="pre">Fifo</span></code> and <code class="docutils literal notranslate"><span class="pre">Trigger</span></code>. A Fifo is a circular buffer that shared between the GPU and the CPU. It is used to store <code class="docutils literal notranslate"><span class="pre">Trigger</span></code>. A <code class="docutils literal notranslate"><span class="pre">Trigger</span></code> is a signal that is sent from the GPU to the CPU to notify the CPU that there are commands in the Fifo that need to be processed. The CPU will then process the commands in the Fifo and send a signal back to the GPU to notify the GPU that the commands have been processed. The implementation details of Fifo and Trigger can be found in following sections.</p>
</section>
<section id="proxyservice">
<h3>ProxyService<a class="headerlink" href="#proxyservice" title="Permalink to this heading"></a></h3>
<p>Proxy service is a persistent service that resides in the CPU side. It functions as a polling service that receives the message <code class="docutils literal notranslate"><span class="pre">Trigger</span></code> from the GPU side and then transfers data according to the command.  When we use <code class="docutils literal notranslate"><span class="pre">ProxyChannel</span></code> for communication, a <code class="docutils literal notranslate"><span class="pre">Trigger</span></code> is sent from the GPU side to the <code class="docutils literal notranslate"><span class="pre">ProxyService</span></code>. Then <code class="docutils literal notranslate"><span class="pre">ProxyService</span></code> will invoke <code class="docutils literal notranslate"><span class="pre">cudaMemcpy*</span></code> or <code class="docutils literal notranslate"><span class="pre">IB</span> <span class="pre">verbs</span></code> to transfer data to the targe device.</p>
</section>
</section>
<section id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this heading"></a></h2>
<p>The core of MSCCL++ is implemented in C++ and CUDA. We offer both C++ and Python APIs for initializing communication channels. For interactions within the GPU kernel, we offer a collection of low-level device functions. Subsequent sections will delve into these interfaces and the methodology for transferring communication logic from the GPU to the CPU.</p>
<section id="interfaces">
<h3>Interfaces<a class="headerlink" href="#interfaces" title="Permalink to this heading"></a></h3>
<p>This section delivers a comprehensive overview of the MSCCL++ interfaces, encompassing both the setup and initialization of communication channels and the MSCCL++ kernel programming model.</p>
<section id="communication-setup-and-initialization-apis">
<h4>Communication setup and initialization APIs<a class="headerlink" href="#communication-setup-and-initialization-apis" title="Permalink to this heading"></a></h4>
<p>MSCCL++ provides APIs in both C++ and Python for establishing communication channels, with further information available in the <a class="reference internal" href="../getting-started/tutorials/initialization.html"><span class="std std-doc">Initialization</span></a> section. Presently, it supports two types of transports: <code class="docutils literal notranslate"><span class="pre">cudaIPC</span></code> for <code class="docutils literal notranslate"><span class="pre">NVLink/xGMI</span></code>, and <code class="docutils literal notranslate"><span class="pre">IB</span></code> for <code class="docutils literal notranslate"><span class="pre">InfiniBand</span></code>. Users are empowered to select the connection type that best suits their hardware infrastructure.</p>
</section>
<section id="msccl-kernel-programming-model">
<h4>MSCCL++ kernel programming model<a class="headerlink" href="#msccl-kernel-programming-model" title="Permalink to this heading"></a></h4>
<p>MSCCL++ offers one-sided communication methods directly callable from a GPU kernel, encompassing two primary API categories: data copy and synchronization. The data copy API features functions such as <code class="docutils literal notranslate"><span class="pre">put()</span></code>, <code class="docutils literal notranslate"><span class="pre">get()</span></code>, <code class="docutils literal notranslate"><span class="pre">read()</span></code>, and <code class="docutils literal notranslate"><span class="pre">write()</span></code>, while the synchronization API comprises <code class="docutils literal notranslate"><span class="pre">signal()</span></code>, <code class="docutils literal notranslate"><span class="pre">flush()</span></code>, and <code class="docutils literal notranslate"><span class="pre">wait()</span></code>. Demonstrated below, the basic utilization of the data copy API involves the <code class="docutils literal notranslate"><span class="pre">put()</span></code> method, which facilitates the transfer of 1KB of data from a local GPU to a remote GPU. Then send a signal to remote peer to notify the data is ready to use. To receive the data, the remote peer can call <code class="docutils literal notranslate"><span class="pre">wait()</span></code> method.
This operation is executed within a kernel launched with a single block.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Running on rank 0</span>
<span class="n">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">gpuKernel</span><span class="p">(</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SmChannelDeviceHandle</span><span class="o">*</span><span class="w"> </span><span class="n">smChannel</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">smChannel</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">put</span><span class="p">(</span><span class="cm">/*dstOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*srcOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*size=*/</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="cm">/*threadId*/</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="cm">/*numThreads*/</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
<span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">smChannel</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">signal</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>

<span class="c1">// Running on rank 1</span>
<span class="n">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">gpuKernel</span><span class="p">(</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SmChannelDeviceHandle</span><span class="o">*</span><span class="w"> </span><span class="n">smChannel</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">smChannel</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">wait</span><span class="p">();</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="n">__syncthreads</span><span class="p">();</span>
<span class="w">  </span><span class="c1">// Data is ready to use</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Similar to the LL protocol offered by NCCL, MSCCL++ introduces a <code class="docutils literal notranslate"><span class="pre">Packet</span></code> structure designed to facilitate the transfer of both data and flags within a single instruction, proving particularly beneficial for applications where latency is a critical concern. The following code shows the basic usage of the <code class="docutils literal notranslate"><span class="pre">Packet</span></code> structure. The flag should be same for sender and receiver side.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="c1">// Running on rank 0</span>
<span class="n">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">gpuKernel</span><span class="p">(</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SmChannelDeviceHandle</span><span class="o">*</span><span class="w"> </span><span class="n">smChans</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">flag</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">smChans</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">putPackets</span><span class="p">(</span><span class="cm">/*dstOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*srcOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*size=*/</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="cm">/*threadId*/</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="cm">/*numThreads*/</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">,</span>
<span class="w">                        </span><span class="cm">/*flag=*/</span><span class="w"> </span><span class="n">flag</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// Running on rank 1</span>
<span class="n">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">gpuKernel</span><span class="p">(</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SmChannelDeviceHandle</span><span class="o">*</span><span class="w"> </span><span class="n">smChans</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">flag</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="n">smChans</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">getPackets</span><span class="p">(</span><span class="cm">/*dstOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*srcOffset=*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*size=*/</span><span class="w"> </span><span class="mi">1024</span><span class="p">,</span><span class="w"> </span><span class="cm">/*threadId*/</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="cm">/*numThreads*/</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">,</span>
<span class="w">                        </span><span class="cm">/*flag=*/</span><span class="w"> </span><span class="n">flag</span><span class="p">);</span>
<span class="w">  </span><span class="c1">// Data is ready to use</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="the-mechanism-for-offloading-communication-logic-from-the-gpu-to-the-cpu">
<h3>The mechanism for offloading communication logic from the GPU to the CPU<a class="headerlink" href="#the-mechanism-for-offloading-communication-logic-from-the-gpu-to-the-cpu" title="Permalink to this heading"></a></h3>
<p>As mentioned in the previous section, the offloading of communication logic from the GPU to the CPU is accomplished through the <code class="docutils literal notranslate"><span class="pre">Fifo</span></code> and <code class="docutils literal notranslate"><span class="pre">Trigger</span></code> mechanism.</p>
<p>The accompanying figure details the structure of <code class="docutils literal notranslate"><span class="pre">Tigger</span></code>, employing three bits to denote the operation type: <code class="docutils literal notranslate"><span class="pre">data</span> <span class="pre">transfer</span></code>, <code class="docutils literal notranslate"><span class="pre">signal</span></code>, and <code class="docutils literal notranslate"><span class="pre">flush</span></code>. The remaining fields specify the precise data locations for both local and remote buffers.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">|-------------------|-------------------|-------------------|-----------------|-----------------|---------|-------------------|---------------|</span>
<span class="o">|</span>    <span class="mi">32</span><span class="n">bit</span> <span class="n">size</span>     <span class="o">|</span>  <span class="mi">32</span><span class="n">bit</span> <span class="n">src</span> <span class="n">offset</span> <span class="o">|</span>  <span class="mi">32</span><span class="n">bit</span> <span class="n">dst</span> <span class="n">offset</span> <span class="o">|</span> <span class="mi">9</span><span class="n">bit</span> <span class="n">src</span> <span class="n">mem</span> <span class="nb">id</span> <span class="o">|</span> <span class="mi">9</span><span class="n">bit</span> <span class="n">dst</span> <span class="n">mem</span> <span class="nb">id</span> <span class="o">|</span> <span class="mi">3</span><span class="n">bit</span> <span class="n">op</span> <span class="o">|</span> <span class="mi">10</span><span class="n">bit</span> <span class="n">channel</span> <span class="nb">id</span>  <span class="o">|</span> <span class="mi">1</span><span class="n">bit</span> <span class="n">reserved</span> <span class="o">|</span>
<span class="o">|-------------------|-------------------|-------------------|-----------------|-----------------|---------|-------------------|---------------|</span>
</pre></div>
</div>
<center>The proxy trigger format</center>
<p>Page-locked memory is utilized for the <code class="docutils literal notranslate"><span class="pre">Fifo</span></code>, guaranteeing access by both the CPU and GPU. On the CPU side, a polling thread periodically checks the Fifo for new commands. Upon processing a command, it updates an incremented counter to signal to the GPU that the command has been executed. Users wishing to ensure a command has been processed can invoke <code class="docutils literal notranslate"><span class="pre">flush()</span></code>, which waits for the device-side counter to reflect this update.</p>
</section>
</section>
<section id="use-cases">
<h2>Use Cases<a class="headerlink" href="#use-cases" title="Permalink to this heading"></a></h2>
<p>In this section, we will discuss several use cases that demonstrate the capabilities of MSCCL++.</p>
<section id="overlapping-communication-with-computation">
<h3>Overlapping communication with computation<a class="headerlink" href="#overlapping-communication-with-computation" title="Permalink to this heading"></a></h3>
<p>MSCCL++ enables the offloading of communication logic from the GPU to the CPU, facilitating the overlapping of communication and computation processes. The code snippet provided illustrates this overlapping technique. In the depicted scenario, the GPU emits a signal to the CPU indicating readiness for data transfer. Subsequently, while the GPU continues to execute computation tasks, the CPU initiates the data transfer to the designated target device.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="n">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">gpuKernel</span><span class="p">(</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SimpleProxyChannelDeviceHandle</span><span class="o">*</span><span class="w"> </span><span class="n">proxyChannel</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">tid</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="w">  </span><span class="c1">// Send a trigger to the CPU</span>
<span class="w">  </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">tid</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">proxyChannel</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">putWithSignal</span><span class="p">(</span><span class="cm">/*dstOffset*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*srcOffset*/</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="cm">/*size*/</span><span class="w"> </span><span class="mi">1024</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="w">  </span><span class="c1">// Continue computation</span>
<span class="w">  </span><span class="n">matrixMul</span><span class="p">()</span>
<span class="w">  </span><span class="c1">// ...</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
<section id="fusion-of-communication-and-computation">
<h3>Fusion of communication and computation<a class="headerlink" href="#fusion-of-communication-and-computation" title="Permalink to this heading"></a></h3>
<p>Traditional communication libraries enforce a separation between communication and computation, creating a bottleneck where communication must await the completion of computation, especially when data dependencies exist. In contrast, MSCCL++ leverages its low-level premitives to facilitate the seamless integration of communication with computation. By segmenting the computation into tiles, MSCCL++ enables the simultaneous pipelining of computation and communication tasks. This approach not only mitigates the communication delay by overlapping processes but also significantly improves throughput by leveraging the low-level API for fine-grained control over the hardware, ensuring optimal efficiency.</p>
</section>
<section id="implementing-customized-collective-communication-algorithms">
<h3>Implementing customized collective communication algorithms<a class="headerlink" href="#implementing-customized-collective-communication-algorithms" title="Permalink to this heading"></a></h3>
<p>MCSCL++ offers a low-level communication API, allowing users to design customized collective communication algorithms. The following code demonstrates how to implement a customized All2All algorithm using MSCCL++.</p>
<div class="highlight-cpp notranslate"><div class="highlight"><pre><span></span><span class="k">using</span><span class="w"> </span><span class="n">DeviceHandle</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">mscclpp</span><span class="o">::</span><span class="n">DeviceHandle</span><span class="o">&lt;</span><span class="n">T</span><span class="o">&gt;</span><span class="p">;</span>
<span class="n">__device__</span><span class="w"> </span><span class="kt">void</span><span class="w"> </span><span class="n">localAlltoall</span><span class="p">(</span><span class="n">DeviceHandle</span><span class="o">&lt;</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SimpleProxyChannel</span><span class="o">&gt;*</span><span class="w"> </span><span class="n">proxyChans</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="n">rank</span><span class="p">,</span>
<span class="w">                              </span><span class="kt">int</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="p">,</span><span class="w"> </span><span class="kt">size_t</span><span class="w"> </span><span class="n">nElements</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="kt">int</span><span class="w"> </span><span class="n">remoteRank</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="kt">int</span><span class="p">)</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">rank</span><span class="p">)</span><span class="w"> </span><span class="o">?</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">:</span><span class="w"> </span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">DeviceHandle</span><span class="o">&lt;</span><span class="n">mscclpp</span><span class="o">::</span><span class="n">SimpleProxyChannel</span><span class="o">&gt;</span><span class="w"> </span><span class="n">proxyChan</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">proxyChans</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">remoteRank</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="p">(</span><span class="n">rank</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">proxyChan</span><span class="p">.</span><span class="n">putWithSignalAndFlush</span><span class="p">(</span><span class="n">rank</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">nElements</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span><span class="w"> </span><span class="n">remoteRank</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">nElements</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span>
<span class="w">                                      </span><span class="n">nElements</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">));</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="c1">// wait for the data from GPU (rank-i) % nranksPerNode to arrive</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">remoteRank</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="p">(</span><span class="n">rank</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="p">)</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">nRanksPerNode</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="n">proxyChan</span><span class="p">.</span><span class="n">wait</span><span class="p">();</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">    </span><span class="n">deviceSyncer</span><span class="p">.</span><span class="n">sync</span><span class="p">(</span><span class="n">nRanksPerNode</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">);</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../getting-started/tutorials/python-api.html" class="btn btn-neutral float-left" title="Working with Python API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="nccl-over-mscclpp.html" class="btn btn-neutral float-right" title="NCCL Over MSCCL++" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, MSCCL++ Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>